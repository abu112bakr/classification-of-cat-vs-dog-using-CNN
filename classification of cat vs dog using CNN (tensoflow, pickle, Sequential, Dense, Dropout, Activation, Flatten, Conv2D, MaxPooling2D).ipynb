{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b9890e",
   "metadata": {},
   "source": [
    "# Cat vs Dog Classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905b37b",
   "metadata": {},
   "source": [
    "This project demonstrates the classification of images into two categories: cats and dogs. It utilizes Convolutional Neural Networks (CNN) and is implemented in Python using the TensorFlow library. The data is loaded from image files and preprocessed to train the model for accurate classification.\n",
    "Prerequisites\n",
    "\n",
    "To run this project, you need to have the following libraries installed:\n",
    "\n",
    "    TensorFlow\n",
    "    pickle\n",
    "    Sequential\n",
    "    Dense\n",
    "    Dropout\n",
    "    Activation\n",
    "    Flatten\n",
    "    Conv2D\n",
    "    MaxPooling2D\n",
    "\n",
    "Dataset is first downloaded from the internet and saved in the computer    \n",
    "Dataset link:https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "Dataset location:\"C:/Datasets/petImages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1861da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before we start\n",
    "#gray scale CNN try to make a color CNN\n",
    "#c+rl + enter runs current shell\n",
    "#pip -V\n",
    "\n",
    "#pip install tensorflow\n",
    "#pip install --upgrade tensorflow\n",
    "\n",
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850aa7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#pip install opencv-python\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92756950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS BLOCK JUST TO SEE THE DOGS/CATS\n",
    "DATADIR=\"C:/Datasets/petImages\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7ec533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Datasets/petImages\\Dog\n",
      "C:/Datasets/petImages\\Cat\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "#Tthis block can run independently\n",
    "#making training data  \n",
    "\n",
    "training_data=[]\n",
    "\n",
    "#0 _> dot\n",
    "#1 _> cat\n",
    "DATADIR=\"C:/Datasets/petImages\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "#IMG_SIZE = 50\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)  #path to cats or dogs dir\n",
    "        print(path)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                #we use try because this process throws a bunch of errors\n",
    "                #converting image to array\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) #making all imgage grayscale, color not neeeded\n",
    "                #new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                new_array = cv2.resize(img_array, (50, 50))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            #plt.imshow(img_array, cmap=\"gray\")\n",
    "            #plt.show()\n",
    "            #break\n",
    "        #break\n",
    "    \n",
    "\n",
    "create_training_data()\n",
    "print(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ead5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n",
      "<class 'list'>\n",
      "[[115 160 159 ... 157 148 139]\n",
      " [121 164 166 ... 163 153 146]\n",
      " [124 161 164 ... 168 161 151]\n",
      " ...\n",
      " [155 128  88 ...  81  69  68]\n",
      " [ 87  95  72 ...  77  74  73]\n",
      " [ 75  78  79 ...  75  78  75]]\n",
      "(50, 50)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "print(type(training_data))\n",
    "\n",
    "print(training_data[0][0])\n",
    "print(training_data[0][0].shape)\n",
    "\n",
    "print(training_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243a48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first part of training_data are only Dogs and then only cats\n",
    "\n",
    "#we want to shuffle the data while feeding it to the model\n",
    "import random\n",
    "random.shuffle(training_data)\n",
    "\n",
    "\n",
    "#for sample in training_data[:10]:\n",
    "#    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cbc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is feature and y is label\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "\n",
    "#new\n",
    "#import numpy as np\n",
    "\n",
    "\n",
    "#new\n",
    "\n",
    "\n",
    "IMG_SIZE = 50\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, IMG_SIZE,IMG_SIZE, 1) #-1 is how many feature, any number!. last 1 is because gayscale\n",
    "#last will be 3 if this is a color instead of grayscale CNN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b52786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the data . we can use numpy save or pickle\n",
    "\n",
    "import pickle\n",
    "pickle_out = open(\"x.pickle\", \"wb\")\n",
    "pickle.dump(x, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "#captial x small y lol\n",
    "#lets fix that\n",
    "\n",
    "#test \n",
    "#pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle_out = open(\"x.pickle\", \"wb\")\n",
    "pickle.dump(x, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eccfb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 99],\n",
       "        [ 86],\n",
       "        [ 81],\n",
       "        ...,\n",
       "        [ 83],\n",
       "        [ 95],\n",
       "        [ 95]],\n",
       "\n",
       "       [[ 77],\n",
       "        [110],\n",
       "        [ 83],\n",
       "        ...,\n",
       "        [ 91],\n",
       "        [ 94],\n",
       "        [106]],\n",
       "\n",
       "       [[106],\n",
       "        [ 83],\n",
       "        [ 87],\n",
       "        ...,\n",
       "        [ 89],\n",
       "        [106],\n",
       "        [106]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[147],\n",
       "        [149],\n",
       "        [157],\n",
       "        ...,\n",
       "        [178],\n",
       "        [175],\n",
       "        [187]],\n",
       "\n",
       "       [[156],\n",
       "        [150],\n",
       "        [153],\n",
       "        ...,\n",
       "        [184],\n",
       "        [173],\n",
       "        [175]],\n",
       "\n",
       "       [[143],\n",
       "        [155],\n",
       "        [149],\n",
       "        ...,\n",
       "        [190],\n",
       "        [179],\n",
       "        [179]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see if we can open what we just have saved \n",
    "pickle_in = open(\"x.pickle\",\"rb\")\n",
    "x = pickle.load(pickle_in)\n",
    "\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68cee3",
   "metadata": {},
   "source": [
    "# Now the classification part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980dfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40aa932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "680bbe36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6138f64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e69a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1690035033\n",
      "Epoch 1/10\n",
      "546/546 [==============================] - 31s 55ms/step - loss: 0.6492 - accuracy: 0.6187 - val_loss: 0.5988 - val_accuracy: 0.6824\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 32s 58ms/step - loss: 0.5626 - accuracy: 0.7133 - val_loss: 0.5663 - val_accuracy: 0.7082\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 30s 55ms/step - loss: 0.5022 - accuracy: 0.7587 - val_loss: 0.5182 - val_accuracy: 0.7413\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 29s 54ms/step - loss: 0.4617 - accuracy: 0.7819 - val_loss: 0.4760 - val_accuracy: 0.7668\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 29s 54ms/step - loss: 0.4320 - accuracy: 0.8029 - val_loss: 0.4758 - val_accuracy: 0.7690\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 30s 55ms/step - loss: 0.3940 - accuracy: 0.8212 - val_loss: 0.4468 - val_accuracy: 0.7866\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 29s 52ms/step - loss: 0.3606 - accuracy: 0.8391 - val_loss: 0.4516 - val_accuracy: 0.7879\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 32s 58ms/step - loss: 0.3349 - accuracy: 0.8522 - val_loss: 0.4245 - val_accuracy: 0.8025\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 29s 52ms/step - loss: 0.3067 - accuracy: 0.8676 - val_loss: 0.4220 - val_accuracy: 0.8040\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 28s 51ms/step - loss: 0.2845 - accuracy: 0.8788 - val_loss: 0.4201 - val_accuracy: 0.8159\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pickle_in = open(\"x.pickle\",\"rb\")\n",
    "x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#consider normalizing the data. this is done by scale the data\n",
    "#so min 0 max 255px\n",
    "#so to scale\n",
    "x=x/255.0\n",
    "#x=x/200.0\n",
    "\n",
    "\n",
    "dense_layers=[0]\n",
    "layer_sizes=[64,]\n",
    "conv_layers=[3]\n",
    "\n",
    "# dense_layers = [0, 1, 2]\n",
    "# layer_sizes = [32, 64, 128]\n",
    "# conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:           #  \n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            #LAYER 1\n",
    "            #conv layer = 64 unit, window = 3 by 3, input shape\n",
    "            # (3,3) is the 3 by 3 window\n",
    "            #model.add( Conv2D(64, (3,3), input_shape = x.shape[1:]) )\n",
    "            model.add( Conv2D(layer_size, (3,3), input_shape = x.shape[1:]) )\n",
    "            #after convotuional layer we are going to pass activation layer\n",
    "            model.add(Activation(\"relu\")) #actitation= rectifi linear\n",
    "            #now we will do pooling\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer -1):\n",
    "                #\n",
    "\n",
    "                #doing this again\n",
    "\n",
    "                #Layer2\n",
    "                #model.add(Conv2D(64, (3,3)))\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                #\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #LAYER4 OUTPUT LAYER\n",
    "            #now to make output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            #y_pred? \n",
    "            #back propagation where? ANN, SGD, Momen\n",
    "            model.compile(loss=\"binary_crossentropy\", \n",
    "                          optimizer=\"adam\", \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "            #import numpy as np\n",
    "\n",
    "            x = np.array(x)\n",
    "            y = np.array(y)\n",
    "\n",
    "            # Rest of your code...\n",
    "\n",
    "            #model.fit(x, y, batch_size=32, validation_split=0.1)   #model.fit(x, y, batch_size=32, epochs=10,validation_split=0.3)\n",
    "            model.fit(x, y, batch_size=32, epochs=10,validation_split=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with  dense_layers=[0] layer_sizes=[64,] conv_layers=[3] validation split 0.3 we got val accuracy: 0.612\n",
    "# and epochs = 10. we got 0.8159 accuracy\n",
    "#maybe overfeeting happening\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98071614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275a099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
